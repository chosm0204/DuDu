from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
import os
import glob
import json
import urllib.parse
from dotenv import load_dotenv 
import random
import time
import shutil
import uuid
import re  # âœ… ì •ê·œí‘œí˜„ì‹ ëª¨ë“ˆ ì¶”ê°€

# RAG ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold

# =========================================================
# ğŸ› ï¸ .env íŒŒì¼ ê°•ì œ ë¡œë“œ
# =========================================================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
ENV_PATH = os.path.join(BASE_DIR, ".env")

if os.path.exists(ENV_PATH):
    load_dotenv(ENV_PATH)
    print(f"âœ… .env ë¡œë“œë¨: {ENV_PATH}")
else:
    print(f"ğŸš¨ .env ì—†ìŒ: {ENV_PATH}")

# =========================================================

app = Flask(__name__)
app.secret_key = os.environ.get("SECRET_KEY", "super-secret-key")
CORS(app)

conversation_history = {}

# --- RAG ì„¤ì • ---
vector_db = None 
DATA_FOLDER = os.path.join(BASE_DIR, "data")
DB_PATH = os.path.join(BASE_DIR, "chroma_db")
DB_INFO_FILE = os.path.join(DB_PATH, "db_info.json")

def get_latest_file_time():
    text_files = glob.glob(os.path.join(DATA_FOLDER, "*.txt"))
    if not text_files: return 0
    return max(os.path.getmtime(f) for f in text_files)

def setup_rag_pipeline():
    global vector_db
    print("ğŸ” RAG ì ê²€ ì¤‘...")

    if not os.path.exists(DATA_FOLDER):
        os.makedirs(DATA_FOLDER)
        print(f"ğŸ“ '{DATA_FOLDER}' ìƒì„±ë¨. .txt íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.")

    latest_mtime = get_latest_file_time()
    need_rebuild = True
    
    if os.path.exists(DB_PATH) and os.path.exists(DB_INFO_FILE):
        try:
            with open(DB_INFO_FILE, "r") as f:
                info = json.load(f)
                if latest_mtime <= info.get("build_time", 0) and latest_mtime > 0:
                    need_rebuild = False
        except: pass

    model_name = "jhgan/ko-sroberta-multitask" 
    embedding_model = SentenceTransformerEmbeddings(model_name=model_name)

    if not need_rebuild and os.path.exists(DB_PATH):
        print(f"âš¡ ê¸°ì¡´ DB ë¡œë“œ ì™„ë£Œ")
        vector_db = Chroma(persist_directory=DB_PATH, embedding_function=embedding_model)
        return

    print("ğŸ”„ DB ì¬í•™ìŠµ ì‹œì‘...")
    if os.path.exists(DB_PATH):
        try: shutil.rmtree(DB_PATH)
        except: pass
        
    text_files = glob.glob(os.path.join(DATA_FOLDER, "*.txt"))
    documents = []
    if text_files:
        for file_path in text_files:
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    documents.append(f.read())
            except: pass

    if not documents:
        print("âš ï¸ ë°ì´í„° ì—†ìŒ (ë¹ˆ DB)")
        return

    full_text = "\n\n".join(documents)
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    text_chunks = text_splitter.split_text(full_text)
    
    vector_db = Chroma.from_texts(texts=text_chunks, embedding=embedding_model, persist_directory=DB_PATH)
    
    if not os.path.exists(DB_PATH): os.makedirs(DB_PATH)
    with open(DB_INFO_FILE, "w") as f: json.dump({"build_time": time.time()}, f)
    print("ğŸ‰ DB ì—…ë°ì´íŠ¸ ì™„ë£Œ!")

# =========================================================
# ğŸ›¡ï¸ 1ì°¨ ë°©ì–´: ê¸ˆì§€ì–´ ë¦¬ìŠ¤íŠ¸
# =========================================================
BANNED_WORDS = ["ë°”ë³´", "ë©ì²­ì´", "ì”¨ë°œ", "ê°œìƒˆë¼", "ë³‘ì‹ ", "ì£½ì–´", "ë¯¸ì¹œ", "ì¡´ë‚˜", "ì¡¸ë¼", "ì•¼ë™", "19ê¸ˆ", "êº¼ì ¸", "ë‹¥ì³"] 

def check_profanity(text):
    for word in BANNED_WORDS:
        if word in text:
            return True
    return False

# =========================================================
# ğŸ¨ ì´ë¯¸ì§€ ìƒì„± ì„¤ì • (ê¸€ì/ìƒí‘œ ê°•ë ¥ ì°¨ë‹¨)
# ğŸ”¥ [ìˆ˜ì •] Stable Diffusion XL ëª¨ë¸ í”„ë¡¬í”„íŠ¸ë¡œ ì „í™˜ ë° í…ìŠ¤íŠ¸ ê¸ˆì§€ ê°•í™”
# =========================================================
# 1. ìŠ¤íƒ€ì¼: ë§¤ëˆí•œ ì¬ì§ˆ, ìƒí‘œ ì—†ìŒ, ì‚¬ë¬¼ë§Œ, ê¹¨ë—í•œ ë°°ê²½
STYLE_DESC = "cute 3D isometric icon, toy-like texture, unbranded, object only, vibrant colors, soft lighting, minimalism, white background, clean image, no packaging, simplified surfaces, NO TEXT"

# 2. ë¶€ì • í”„ë¡¬í”„íŠ¸: ê¸€ì, ìƒí‘œ, ë¡œê³  ì ˆëŒ€ ê¸ˆì§€
# ğŸ”¥ [ìˆ˜ì •] SDXLì—ì„œ íš¨ê³¼ì ì¸ í…ìŠ¤íŠ¸ ê¸ˆì§€ í‚¤ì›Œë“œì™€ ë§¤ìš° ë†’ì€ ê°€ì¤‘ì¹˜ ì‚¬ìš© (2.9)
NEGATIVE_DESC = "(watermark:2.9), (text:2.9), (writing:2.9), (letters:2.9), (alphabet:2.9), (numbers:2.9), (typography:2.9), signature, logo, brand name, trademark, label, caption, blurry, distorted, human, face, texture with text, pattern with text, background with text"

# --- API ---

@app.route("/")
def home():
    return "DuDu Backend (Dictionary & Safety Features) Running!"

@app.route("/search", methods=["GET"])
def handle_search():
    query = request.args.get("query")
    session_id = request.args.get("session_id")
    
    if not query: return jsonify({"error": "ê²€ìƒ‰ì–´ ì—†ìŒ"}), 400
    if not session_id: session_id = str(uuid.uuid4())
    if session_id not in conversation_history: conversation_history[session_id] = []

    # 1. [1ì°¨ ë°©ì–´] ìš•ì„¤ ê°ì§€ -> ì´ë¯¸ì§€ ìƒì„± ì•ˆ í•¨ ("")
    if check_profanity(query):
        print(f"ğŸš¨ ìš•ì„¤ ê°ì§€ë¨: {query}")
        return jsonify({
            "answer": [{
                "title": "ë‘ë‘ê°€ ì†ìƒí•´ìš” ğŸ˜¢", 
                "content": "ì¹œêµ¬ì•¼, ê·¸ëŸ° ë§ì„ ë“¤ìœ¼ë‹ˆ ë§ˆìŒì´ ì•„íŒŒìš”.\nìš°ë¦¬ ì„œë¡œì—ê²Œ í˜ì´ ë˜ëŠ” ê³ ìš´ ë§ë§Œ ì“°ê¸°ë¡œ í•´ìš”! ğŸ¤™", 
                "image_url": "", 
                "image_keyword": "warning"
            }],
            "dictionary": [],
            "follow_up_questions": [],
            "summary": "ìš•ì„¤ ê²½ê³ "
        })

    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key: return jsonify({"error": "API Key ì˜¤ë¥˜"}), 500
    
    genai.configure(api_key=api_key)

    # 2. RAG ê²€ìƒ‰ (ë””ë²„ê¹…ìš© ì¶œë ¥ í¬í•¨)
    print(f"\nğŸ” [RAG ê²€ìƒ‰ ì‹œì‘] ì§ˆë¬¸: '{query}'")
    context = ""
    if vector_db:
        try:
            docs = vector_db.similarity_search(query, k=3)
            if docs: 
                print(f"âœ… ì°¸ê³  ìë£Œ {len(docs)}ê°œ ë°œê²¬!")
                for i, doc in enumerate(docs):
                    print(f"   ğŸ“„ [ìë£Œ {i+1}] {doc.page_content[:50]}...")
                context = "\n\n".join([d.page_content for d in docs])
            else:
                print("âš ï¸ ê²€ìƒ‰ëœ ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤.")
        except: pass

    history_text = ""
    for item in conversation_history.get(session_id, [])[-3:]:
        history_text += f"í•™ìƒ: {item['question']}\në‘ë‘: {item['summary']}\n"

    # 3. í”„ë¡¬í”„íŠ¸ (ë‹¨ì–´ì¥ ê¸°ëŠ¥ + 3ë‹¨ êµ¬ì„± + ì•ˆì „ ê·œì¹™ + ê¸€ì ê¸ˆì§€)
    prompt = f"""
    ë‹¹ì‹ ì€ ì´ˆë“±í•™ìƒ(8~13ì„¸)ì˜ ëˆˆë†’ì´ì— ë§ì¶° ì„¤ëª…í•´ ì£¼ëŠ” ì¹œì ˆí•œ AI ì„ ìƒë‹˜ 'ë‘ë‘'ì…ë‹ˆë‹¤.
    
    [ì´ì „ ëŒ€í™”]
    {history_text}
    
    [ì§ˆë¬¸]: "{query}"
    [ì°¸ê³  ìë£Œ]: {context if context else "ì—†ìŒ"}

    [ê·œì¹™]
    1. **ì•ˆì „ ì œì¼:** í­ë ¥, ì„ ì •, í˜ì˜¤ í‘œí˜„ì—ëŠ” ì ˆëŒ€ ëŒ€ë‹µí•˜ì§€ ë§ˆì„¸ìš”.
    2. **ì ˆëŒ€ ê·œì¹™:** ì˜¤ì§ [ì°¸ê³  ìë£Œ]ì— ìˆëŠ” ë‚´ìš©ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.
    3. **ëª¨ë¦„ ì²˜ë¦¬:** ìë£Œì— ì—†ìœ¼ë©´ ì†”ì§í•˜ê²Œ ëª¨ë¥¸ë‹¤ê³  í•˜ê³ , **image_keywordëŠ” 'UNKNOWN'**ìœ¼ë¡œ ì ìœ¼ì„¸ìš”.
    4. **ì´ë¯¸ì§€ í‚¤ì›Œë“œ:** ì„¤ëª…í•˜ëŠ” ì‚¬ë¬¼ì„ **'ë¸Œëœë“œ ì—†ëŠ” ì¼ë°˜ì ì¸(Generic) ì˜ì–´ ë‹¨ì–´'**ë¡œ ë¬˜ì‚¬í•˜ì„¸ìš”. **ì ˆëŒ€ íŠ¹ìˆ˜ë¬¸ìë‚˜ ê´„í˜¸ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.**
    5. **ê¼¬ë¦¬ ì§ˆë¬¸ ê·œì¹™:** `follow_up_questions`ì€ ë°˜ë“œì‹œ ì œê³µëœ [ì°¸ê³  ìë£Œ]ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ì´ì–´ì•¼ í•©ë‹ˆë‹¤. ìë£Œì— ì—†ëŠ” ë‚´ìš©ì€ ì§ˆë¬¸í•˜ì§€ ë§ˆì„¸ìš”.
    6. **â­ ê¼¬ë¦¬ ì§ˆë¬¸ ìƒì„± ê°•í™” (NEW):** `follow_up_questions`ì„ ë§Œë“¤ ë•Œ, [ì°¸ê³  ìë£Œ] ë‚´ì— **ì§ì ‘ì ìœ¼ë¡œ ì–¸ê¸‰ëœ í•µì‹¬ ì£¼ì–´(Subject)ì™€ ëª…ì‚¬**ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸í•˜ì„¸ìš”. ì´ëŠ” ê²€ìƒ‰ ì •í™•ë„ë¥¼ ë†’ì—¬ ë‹µë³€ ì‹¤íŒ¨ë¥¼ ì¤„ì…ë‹ˆë‹¤.

    [ì¹´ë“œ êµ¬ì„± ê·œì¹™ - ë°˜ë“œì‹œ ì§€í‚¤ì„¸ìš”!]
    1. **ì²« ë²ˆì§¸ ì¹´ë“œ:** ì§ˆë¬¸ì— ëŒ€í•œ **'ê°„ë‹¨í•˜ê³  ëª…í™•í•œ í•µì‹¬ ë‹µë³€'** (3ë¬¸ì¥ ì´ë‚´)
    2. **ë‘ ë²ˆì§¸ ì¹´ë“œ:** ì²« ë²ˆì§¸ ë‚´ìš©ì„ ë³´ì¶©í•˜ëŠ” **'ìì„¸í•œ ì„¤ëª…ì´ë‚˜ ì˜ˆì‹œ'**
    3. **ì„¸ ë²ˆì§¸ ì¹´ë“œ:** ì´ ì£¼ì œì™€ ì—°ê´€ëœ **'ë‹¤ë¥¸ ì¬ë¯¸ìˆëŠ” ì£¼ì œ ì¶”ì²œ'** ë˜ëŠ” 'í¥ë¯¸ë¡œìš´ ì‚¬ì‹¤'

    [â˜… ë‹¨ì–´ì¥ ê¸°ëŠ¥]
    ë‹µë³€ ë‚´ìš© ì¤‘ ì´ˆë“±í•™ìƒì´ ì–´ë ¤ì›Œí•  ë§Œí•œ ë‹¨ì–´(ì˜ˆ: ê³µì „, ë°€ë„, ê´‘í•©ì„± ë“±)ê°€ ìˆë‹¤ë©´,
    ê·¸ ë‹¨ì–´ì™€ ì‰¬ìš´ ëœ»í’€ì´ë¥¼ `dictionary` ë¦¬ìŠ¤íŠ¸ì— ë‹´ì•„ì£¼ì„¸ìš”. (ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸)

    [í•„ìˆ˜ í˜•ì‹: JSON]
    ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ ì—†ì´ ì•„ë˜ JSON í¬ë§·ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
    {{
        "cards": [
            {{ "title": "í•µì‹¬ ì™ì™!", "content": "ë‚´ìš©...", "image_keyword": "Generic object description 1 or UNKNOWN" }},
            {{ "title": "ìì„¸íˆ ì•Œì•„ë´ìš”!", "content": "ë‚´ìš©...", "image_keyword": "Generic object description 2 or UNKNOWN" }},
            {{ "title": "ì´ê±´ ì–´ë•Œìš”?", "content": "ë‚´ìš©...", "image_keyword": "Generic object description 3 or UNKNOWN" }}
        ],
        "dictionary": [
            {{ "word": "ì–´ë ¤ìš´ë‹¨ì–´1", "meaning": "ì‰¬ìš´ ëœ»í’€ì´" }},
            {{ "word": "ì–´ë ¤ìš´ë‹¨ì–´2", "meaning": "ì‰¬ìš´ ëœ»í’€ì´" }}
        ],
        "follow_up_questions": ["ì§ˆë¬¸1", "ì§ˆë¬¸2"],
        "summary": "ìš”ì•½"
    }}
    """
    
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        
        # ğŸ›¡ï¸ [3ì°¨ ë°©ì–´] ì•ˆì „ í•„í„°
        safety_settings = {
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,
        }

        response = model.generate_content(prompt, safety_settings=safety_settings)
        
        # ì•ˆì „ í•„í„° ì°¨ë‹¨ ì‹œ -> ì´ë¯¸ì§€ ì—†ìŒ
        if not response.parts:
            return jsonify({
                "answer": [{"title":"ìœ„í—˜í•´ìš”! ğŸ›¡ï¸", "content":"ì¹œêµ¬ì•¼, ê·¸ ì§ˆë¬¸ì€ ì¡°ê¸ˆ ìœ„í—˜í•œ ê²ƒ ê°™ì•„. ë‹¤ë¥¸ ê±¸ ë¬¼ì–´ë´ ì¤„ë˜?", "image_url":"", "image_keyword":"shield"}],
                "dictionary": [],
                "follow_up_questions": [],
                "summary": "ìœ í•´ ì½˜í…ì¸  ì°¨ë‹¨"
            })

        text = response.text.replace("```json", "").replace("```", "")
        try:
            data = json.loads(text)
        except:
            data = {
                "cards": [{"title":"ì˜¤ë¥˜", "content":"ì ì‹œ ë¬¸ì œê°€ ìƒê²¼ì–´ìš”.", "image_keyword":"UNKNOWN"}], 
                "dictionary": [],
                "follow_up_questions":[], 
                "summary":"ì—ëŸ¬"
            }

        # 5. ì´ë¯¸ì§€ ìƒì„± (ìƒí‘œ/ê¸€ì ì œê±° ê°•í™” + ëª¨ë¦„ ì²˜ë¦¬)
        processed_cards = []
        session_seed = random.randint(1000, 9999)

        cards = data.get("cards", [])
        if not cards: cards = [{"title":"ì•Œ ìˆ˜ ì—†ìŒ", "content":"ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”.", "image_keyword":"UNKNOWN"}]

        for i, card in enumerate(cards):
            keyword = card.get("image_keyword", "UNKNOWN")
            
            # UNKNOWN ì²˜ë¦¬ -> ë¬¼ìŒí‘œ ì•„ì´ì½˜
            if keyword == "UNKNOWN" or "unknown" in keyword.lower():
                final_prompt = f"cute 3D isometric question mark, puzzle piece, curiosity, {STYLE_DESC}, {NEGATIVE_DESC}"
            else:
                # 'generic', 'unbranded' ê°•ì œ ì¶”ê°€ë¡œ íŠ¹ì • ìƒí‘œ ë°©ì§€
                clean_keyword = f"generic {keyword}, single object, unbranded, no text"
                final_prompt = f"{clean_keyword}, {STYLE_DESC}, {NEGATIVE_DESC}"
            
            encoded_prompt = urllib.parse.quote_plus(final_prompt)
            
            # ğŸ”¥ [ìˆ˜ì • ì—†ìŒ] Stable Diffusion XL ëª¨ë¸ì„ ì‚¬ìš©í•˜ë„ë¡ ìš”ì²­
            card['image_url'] = f"https://image.pollinations.ai/prompt/{encoded_prompt}?model=stable-diffusion-xl-1024-v1-0&width=800&height=600&seed={session_seed + i}&nologo=true&negative_prompt={urllib.parse.quote_plus(NEGATIVE_DESC)}"
            processed_cards.append(card)

        conversation_history[session_id].append({"question": query, "summary": data.get("summary", "")})

        # âœ… dictionary ë°ì´í„°ë„ í•¨ê»˜ ì „ì†¡
        return jsonify({
            "answer": processed_cards, 
            "dictionary": data.get("dictionary", []), 
            "follow_up_questions": data.get("follow_up_questions", [])
        })

    except Exception as e:
        print(f"ğŸš¨ ì—ëŸ¬ ë°œìƒ: {str(e)}")
        return jsonify({
            "answer": [{"title":"ì˜¤ë¥˜", "content":"ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”.", "image_url":""}],
            "dictionary": [],
            "follow_up_questions": []
        })

# =========================================================
# ğŸ’¡ [ìˆ˜ì •] ì¶”ì²œ ì§ˆë¬¸ ìƒì„± API (ê³¼ëª©ë³„ íŒŒì¼ í•„í„°ë§ ì¶”ê°€)
# =========================================================
@app.route("/recommendations", methods=["GET"])
def get_recommendations():
    # ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ë¡œ ê³¼ëª© ë°›ê¸° (ì—†ìœ¼ë©´ general)
    subject = request.args.get("subject")
    if not subject: subject = "general"
    
    print(f"ğŸ’¡ ì¶”ì²œ ì§ˆë¬¸ ìš”ì²­ ë°›ìŒ (ê³¼ëª©: {subject})")
    
    # ê³¼ëª©ë³„ ìºì‹œ íŒŒì¼ ë¶„ë¦¬
    CACHE_FILE = os.path.join(BASE_DIR, f"recommendations_cache_{subject}.json")
    CACHE_DURATION = 3600  # 1ì‹œê°„
    
    default_questions = [
        "ğŸ¦– ê³µë£¡ì€ ì™œ ì‚¬ë¼ì¡Œì„ê¹Œ?", "ğŸŒˆ ë¬´ì§€ê°œëŠ” ì–´ë–»ê²Œ ìƒê²¨?", 
        "ğŸ¤– ë¡œë´‡ë„ ê°ì •ì´ ìˆì„ê¹Œ?", "ğŸš€ ìš°ì£¼ëŠ” ì–¼ë§ˆë‚˜ ë„“ì–´?",
        "ğŸ¦· ì´ë¹¨ì€ ì™œ ë¹ ì§€ëŠ” ê±°ì•¼?", "ğŸ³ ê³ ë˜ëŠ” ë¬¼ê³ ê¸°ê°€ ì•„ë‹ˆì•¼?"
    ]

    # 1. ìºì‹œ í™•ì¸
    if os.path.exists(CACHE_FILE):
        try:
            with open(CACHE_FILE, "r", encoding="utf-8") as f:
                file_mod_time = os.path.getmtime(CACHE_FILE)
                if time.time() - file_mod_time < CACHE_DURATION:
                    all_questions = json.load(f)
                    if all_questions and isinstance(all_questions, list):
                        selected_questions = random.sample(all_questions, min(len(all_questions), 6))
                        print(f"ğŸš€ ìºì‹œëœ ë°ì´í„°ì—ì„œ ëœë¤ ë°˜í™˜ ì™„ë£Œ (ê³¼ëª©: {subject})")
                        return jsonify(selected_questions)
        except Exception as e:
            print(f"âš ï¸ ìºì‹œ ì½ê¸° ì‹¤íŒ¨: {e}")

    # 2. ìºì‹œ ì—†ìœ¼ë©´ ìƒì„± (Gemini í˜¸ì¶œ)
    try:
        # âœ… ê³¼ëª© ì½”ë“œì™€ í•œê¸€ í‚¤ì›Œë“œ ë§¤í•‘
        alternate_keywords = ["ì‹¤ê³¼", "ì²´ìœ¡", "ë¯¸ìˆ ", "ìŒì•…", "ë„ë•"]
        
        keyword_map = {
            "math": ["ìˆ˜í•™"],
            "science": ["ê³¼í•™"],
            "society": ["ì‚¬íšŒ"],
            "english": ["ì˜ì–´"],
            "korean": alternate_keywords,
            "history": alternate_keywords
        }
        
        target_keywords = keyword_map.get(subject)
        
        # ëª¨ë“  í…ìŠ¤íŠ¸ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
        all_text_files = glob.glob(os.path.join(DATA_FOLDER, "*.txt"))
        
        target_files = []
        
        if subject == "general" or not target_keywords:
            target_files = all_text_files
        else:
            for f in all_text_files:
                for kw in target_keywords:
                    if kw in os.path.basename(f):
                        target_files.append(f)
                        break
            
            if not target_files:
                print(f"âš ï¸ {subject} ê´€ë ¨ íŒŒì¼ ì—†ìŒ. ì „ì²´ íŒŒì¼ ì¤‘ ëœë¤ ì„ íƒ.")
                target_files = all_text_files

        if not target_files:
            return jsonify(default_questions)

        # í•„í„°ë§ëœ íŒŒì¼ë“¤ ì¤‘ì—ì„œ ëœë¤ ì„ íƒ
        selected_file = random.choice(target_files)
        print(f"ğŸ“– ì½ê³  ìˆëŠ” íŒŒì¼: {os.path.basename(selected_file)}")
        
        with open(selected_file, "r", encoding="utf-8") as f:
            full_content = f.read()

        # ğŸ”¥ [ì¶”ê°€] í…ìŠ¤íŠ¸ ì •ì œ (í•œê¸€, ì˜ì–´, ìˆ«ì, ê¸°ë³¸ êµ¬ë‘ì /ê³µë°±ë§Œ ìœ ì§€)
        full_content = re.sub(r"[^ê°€-í£a-zA-Z0-9\s\.\,\?\!]", " ", full_content)
        full_content = re.sub(r"\s+", " ", full_content).strip()  # ì—°ì†ëœ ê³µë°± ì •ë¦¬
            
        # ë‚´ìš©ì´ 3000ìë³´ë‹¤ ê¸¸ë©´ ì¤‘ê°„ ì–´ë”˜ê°€ë¥¼ ëœë¤ìœ¼ë¡œ ìë¦„ (ì•ë¶€ë¶„ ëª©ì°¨ íšŒí”¼)
        if len(full_content) > 3000:
            start_index = random.randint(0, len(full_content) - 3000)
            content = full_content[start_index : start_index + 3000]
        else:
            content = full_content

        api_key = os.environ.get("GEMINI_API_KEY")
        if not api_key: return jsonify(default_questions)
            
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.5-flash')

        # í”„ë¡¬í”„íŠ¸ ì„¤ì • (ê³¼ëª©ë³„ë¡œ ë‹¤ë¥´ê²Œ ì§€ì‹œ)
        if subject in ["korean", "history"]:
            subject_instruction = "ì´ í…ìŠ¤íŠ¸ ë‚´ìš© ì¤‘ì—ì„œ ì•„ì´ë“¤ì´ ê°€ì¥ ì‹ ê¸°í•´í•  ë§Œí•œ ì‚¬ì‹¤ì„ ì°¾ì•„ì„œ ì§ˆë¬¸ìœ¼ë¡œ ë°”ê¿”ì£¼ì„¸ìš”."
        else:
            subject_instruction = f"ì§ˆë¬¸ì€ **{subject}** ê³¼ëª© í•™ìŠµ ë‚´ìš©ê³¼ ê´€ë ¨ë˜ë„ë¡ ë§Œë“¤ì–´ì£¼ì„¸ìš”."
        
        # â­ï¸ [í•µì‹¬ ìˆ˜ì •] ì§ˆë¬¸ í€„ë¦¬í‹°ë¥¼ ë†’ì´ëŠ” ê°•ë ¥í•œ í”„ë¡¬í”„íŠ¸
        prompt = f"""
        ë‹¹ì‹ ì€ ì•„ì´ë“¤ì˜ í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ëŠ” 'í€´ì¦ˆ íƒí—˜ëŒ€ì¥'ì…ë‹ˆë‹¤.
        ì•„ë˜ í…ìŠ¤íŠ¸ëŠ” êµê³¼ì„œì˜ ì¼ë¶€ì…ë‹ˆë‹¤. ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì¹œêµ¬ì—ê²Œ ë‚¼ ìˆ˜ ìˆëŠ” **'ì¬ë¯¸ìˆëŠ” í€´ì¦ˆ ì§ˆë¬¸'** 20ê°œë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
        
        [í…ìŠ¤íŠ¸ ë‚´ìš©]
        {content}
        
        {subject_instruction}

        [â˜…ì§ˆë¬¸ ìƒì„± ê·œì¹™â˜…]
        1. **ë‹¨ìˆœí•œ ì •ì˜ë¥¼ ë¬»ì§€ ë§ˆì„¸ìš”.** (ì˜ˆ: "ê´‘í•©ì„±ì´ë€?" (X) -> "ì‹ë¬¼ì€ ì–´ë–»ê²Œ í–‡ë¹›ì„ ë¨¹ì„ê¹Œ? ğŸŒ¿" (O))
        2. **'ì™œ?' ë˜ëŠ” 'ì–´ë–»ê²Œ?'ë¡œ ì‹œì‘í•˜ëŠ” í˜¸ê¸°ì‹¬ ì§ˆë¬¸**ì„ ìš°ì„ í•˜ì„¸ìš”.
        3. ë°˜ë“œì‹œ **ìœ„ [í…ìŠ¤íŠ¸ ë‚´ìš©] ì•ˆì— ì •ë‹µì´ ìˆëŠ” ë‚´ìš©**ì´ì–´ì•¼ í•©ë‹ˆë‹¤. (ì—†ëŠ” ë‚´ìš© ì§€ì–´ë‚´ê¸° ê¸ˆì§€)
        4. ì–´ë¥¸ìŠ¤ëŸ¬ìš´ ë§íˆ¬ ëŒ€ì‹ , **ì´ˆë“±í•™ìƒì´ ì¹œêµ¬ì—ê²Œ ë¬¼ì–´ë³´ëŠ” ë“¯í•œ ë§íˆ¬**ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
        5. ì§ˆë¬¸ ì•ì—ëŠ” ê´€ë ¨ëœ **ì´ëª¨ì§€**ë¥¼ ê¼­ ë¶™ì—¬ì£¼ì„¸ìš”.
        6. **[ì¤‘ìš”] ì§ˆë¬¸ì€ ë„ì–´ì“°ê¸° í¬í•¨ 25ì ì´ë‚´ë¡œ ë§Œë“œì„¸ìš”.** ["ğŸš€ ìš°ì£¼ì„  ì•ˆì—ì„œëŠ” ì™œ ë‘¥ë‘¥ ë– ë‹¤ë‹ˆê²Œ ë ê¹Œ?", "ğŸœ ê°œë¯¸ëŠ” ì™œ í•­ìƒ ì¤„ì„ ì§€ì–´ ë‹¤ë‹ˆëŠ” ê±¸ê¹Œ?", "ğŸ’¡ ì „êµ¬ëŠ” ì–´ë–»ê²Œ ëœ¨ê±°ì›Œì§€ì§€ ì•Šê³  ë¹›ì„ ë‚¼ê¹Œ?"]

        [ì¶œë ¥ ì˜ˆì‹œ]
        ["ğŸš€ ìš°ì£¼ì„ ì€ ì™œ ë– ë‹¤ë…€?", "ğŸœ ê°œë¯¸ëŠ” ì™œ ì¤„ ì„œ?", "ğŸ’¡ ì „êµ¬ëŠ” ì–´ë–»ê²Œ ë¹›ë‚˜?"]
        
        [í˜•ì‹ ì¡°ê±´]
        ë°˜ë“œì‹œ JSON ë¦¬ìŠ¤íŠ¸ í¬ë§·ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ ì—†ì´ ìˆœìˆ˜ JSONë§Œ ì£¼ì„¸ìš”.
        """

        response = model.generate_content(prompt)
        text = response.text.replace("```json", "").replace("```", "").strip()
        questions = json.loads(text)
        
        if not isinstance(questions, list) or not questions:
            return jsonify(default_questions)

        # 3. ìƒì„±ëœ ì§ˆë¬¸ì„ ìºì‹œ íŒŒì¼ì— ì €ì¥
        with open(CACHE_FILE, "w", encoding="utf-8") as f:
            json.dump(questions, f, ensure_ascii=False)
            
        print(f"ğŸ’¾ ìƒˆ ì§ˆë¬¸ {len(questions)}ê°œ ìƒì„± ë° ìºì‹œ ì €ì¥ ì™„ë£Œ (ê³¼ëª©: {subject})")
        
        # 4. ê·¸ ì¤‘ì—ì„œ 6ê°œ ëœë¤ ë°˜í™˜
        result = random.sample(questions, min(len(questions), 6))
        return jsonify(result)

    except Exception as e:
        print(f"ğŸš¨ ì¶”ì²œ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return jsonify(default_questions)

# ğŸ”„ ì„œë²„ ì‹œì‘ ì‹œ ê¸°ì¡´ ìºì‹œ íŒŒì¼ ì‚­ì œ (í´ë¦° ìŠ¤íƒ€íŠ¸)
if __name__ == '__main__':
    print("ğŸ§¹ ê¸°ì¡´ ì¶”ì²œ ì§ˆë¬¸ ìºì‹œ ì‚­ì œ ì¤‘...")
    cache_files = glob.glob(os.path.join(BASE_DIR, "recommendations_cache_*.json"))
    for f in cache_files:
        try:
            os.remove(f)
            print(f" - ì‚­ì œë¨: {os.path.basename(f)}")
        except Exception as e:
            print(f" - ì‚­ì œ ì‹¤íŒ¨: {e}")

    setup_rag_pipeline()
    app.run(host='0.0.0.0', port=5001, debug=True)